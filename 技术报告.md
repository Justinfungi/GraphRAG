# Technical Reprot

## Overview

GraphRAG implementation and evaluation

## Data preprocess

1. init
   初始化Transformer库里常用的AutoTokenize，AutoModelForCausalLM
   Neo4j用于数据库连接，
   spacy用于NLP的实体识别。

2. extract_entities_relations
   首先，它利用超链接信息提取已知实体并创建基础实体关系。然后，使用LLaMA模型从整个文本中提取更多实体关系。

3. create_graph_nodes和create_graph_relations
   负责在Neo4j数据库中创建图的节点和实体之间的关系。采用事务处理通过MERGE语句避免重复创建节点和关系。

4. process_document
   处理输入段落，调用提取方法获得实体关系，并通过数据库会话将这些信息更新到Neo4j中。这一过程涉及创建所有节点、超链接节点和提取到的新实体关系。

5. build_knowledge_graph
   负责从train.json读取数据，通过循环读取每个段落调用process_document进行实体关系提取和存储。

6. _extract_hyperlinks
   利用spacy进行命名实体识别（NER），提取出文本中的潜在超链接实体，如人名（PERSON）、组织（ORG）等，主要用于补充可以作为图谱节点的实体信息。

## Implementation of Graph RAG

1. __init__
   初始化了用于自然语言生成的LLaMA模型和用于文本嵌入的SentenceTransformer。这些模型分别用于生成自然语言文本和对查询进行语义编码。初始化Neo4j驱动程序以连接到知识图谱数据库，这样可以在后续步骤中查询和获取相关的知识图谱上下文。

2. get_graph_context
  根据输入的查询在Neo4j中检索相关子图上下文。通过对查询进行编码并执行一个Neo4j的Cypher查询语句，它在数据库中寻找符合条件的一到两跳以内的实体路径。

3. _path_to_text
   将Neo4j的路径对象转化为自然语言文本描述。这是通过遍历路径中的节点和关系，将它们描述为句子片段并组合成完整文本。

4. generate_response
  使用获取的图谱上下文和输入的查询构建一个带有上下文信息的提示，将这段提示输入到LLaMA模型中来生成响应。生成的答案作为对输入问题的自然语言回应，并将最后的文本输出返回。

5. close
   用于在程序结束时关闭Neo4j数据库连接，释放资源。

## Evaliution 

1. Source:
   我们模仿 https://github.com/Alab-NII/2wikimultihop/blob/main/2wikimultihop_evaluate_v1.1.py 去实现四个指标
   metrics['em']
    metrics['f1'] 
    metrics['prec']
    metrics['recall']

2. Main result
